# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iuSRSUCDuwM2UUd2lFhOPlGKmDUUrTEG
"""

!pip install textblob
from textblob import TextBlob

!pip install yfinance
!pip install ta
!pip install vaderSentiment
!pip install statsmodels
!pip install newsapi-python

!pip install feedparser
import feedparser

!pip install feedparser

import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
import ta
import requests
from statsmodels.tsa.arima.model import ARIMA
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from newsapi import NewsApiClient







def get_crypto_news(api_key, query='gala OR bitcoin', from_date='2024-12-01', to_date='2024-12-31'):
    url = "https://newsapi.org/v2/everything"
    params = {
        'q': query,
        'from': from_date,
        'to': to_date,
        'language': 'en',
        'sortBy': 'relevancy',
        'pageSize': 20,
        'apiKey': api_key
    }

    response = requests.get(url, params=params)

    if response.status_code != 200:
        print("âš ï¸ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ NewsAPI:", response.status_code, response.text)
        return pd.DataFrame()

    articles = response.json().get('articles', [])
    news_data = []
    for article in articles:
        news_data.append({
            'date': article['publishedAt'][:10],
            'title': article['title'],
            'description': article['description']
        })

    return pd.DataFrame(news_data)

df = yf.download("GALA-USD", period="1y", interval="1d")
df = df[['Close']].rename(columns={'Close': 'close'})
df.dropna(inplace=True)
df.plot(title="GALA/USD - Ø³Ø¹Ø± ÙŠÙˆÙ…ÙŠ Ù…Ù† Yahoo Finance", figsize=(10,4))

df['rsi'] = df['rsi'] = ta.momentum.RSIIndicator(close=df['close'].squeeze()).rsi()
df[['close', 'rsi']].tail()

model = ARIMA(df['close'], order=(3, 1, 2))
model_fit = model.fit()
forecast = model_fit.forecast(steps=7)
print("ğŸ”® ØªÙˆÙ‚Ø¹ Ø§Ù„Ø³Ø¹Ø± Ù„Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©:")
print(forecast)

from datetime import datetime

def fetch_google_news_rss(query="gala crypto"):
    feed_url = f"https://news.google.com/rss/search?q={query.replace(' ', '+')}&hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(feed_url)

    data = []
    for entry in feed.entries:
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†
            date_obj = datetime.strptime(entry.published, "%a, %d %b %Y %H:%M:%S %Z")
            clean_date = date_obj.strftime("%Y-%m-%d")
        except:
            continue  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØ§Ø±ÙŠØ® ØºÙŠØ± ØµØ­ÙŠØ­

        data.append({
            'date': clean_date,
            'title': entry.title,
            'description': entry.summary
        })

    return pd.DataFrame(data)

from textblob import TextBlob

def analyze_sentiment(text):
    if not text:
        return 0
    analysis = TextBlob(text)
    return analysis.sentiment.polarity  # Ù‚ÙŠÙ…Ø© Ø¨ÙŠÙ† -1 (Ø³Ù„Ø¨ÙŠ) Ùˆ +1 (Ø¥ÙŠØ¬Ø§Ø¨ÙŠ)

news_df = fetch_google_news_rss()
news_df['sentiment_score'] = news_df['description'].apply(analyze_sentiment)
news_df['date'] = pd.to_datetime(news_df['date'])  # Ø§Ù„Ø¢Ù† Ø³ØªÙƒÙˆÙ† ÙƒÙ„Ù‡Ø§ ØµØ§Ù„Ø­Ø© Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡

daily_sentiment = news_df.groupby('date')['sentiment_score'].mean()

# ØªØ­ÙˆÙŠÙ„ daily_sentiment Ù…Ù† Series Ø¥Ù„Ù‰ DataFrame ØµØ§Ù„Ø­ Ù„Ù„Ø¯Ù…Ø¬
daily_sentiment_clean = daily_sentiment.reset_index(name='sentiment_score')

# Ø¥Ø²Ø§Ù„Ø© Ø¬Ù…ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ÙÙ‡Ø±Ø³Ø© ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ df Ù†Ù‡Ø§Ø¦ÙŠÙ‹Ø§
df_clean = pd.DataFrame(df.values, columns=df.columns)
df_clean['Date'] = df.index.get_level_values(-1)

# Ø¥Ø¹Ø§Ø¯Ø© ØªÙÙƒÙŠÙƒ df Ø¥Ù„Ù‰ DataFrame ØµØ±ÙŠØ­ 100%
df_clean = pd.DataFrame(df.to_numpy(), columns=df.columns)  # Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù…Ø¤Ø´Ø±
df_clean_dates = df.index.to_frame(index=False)  # Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ ÙƒÙ„ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø¤Ø´Ø± ÙƒÙ…Ø¹Ù„ÙˆÙ…Ø§Øª

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø¨Ø¯Ù‚Ø©
if 'Date' in df_clean_dates.columns:
    df_clean['Date'] = pd.to_datetime(df_clean_dates['Date'])
else:
    df_clean['Date'] = pd.to_datetime(df_clean_dates.iloc[:, -1])  # Ø¢Ø®Ø± Ø¹Ù…ÙˆØ¯ ØºØ§Ù„Ø¨Ù‹Ø§ Ù‡Ùˆ Ø§Ù„ØªØ§Ø±ÙŠØ®

# Ù†ÙÙƒ ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¤Ø´Ø± Ø¥Ù„Ù‰ DataFrame Ù…Ø³Ø·Ø­ 100%
df_index_flat = df.index.to_frame(index=False)  # Ø§Ù„Ù…Ø¤Ø´Ø± ÙƒÙ…Ø¹Ù„ÙˆÙ…Ø§Øª
df_values = pd.DataFrame(df.values, columns=df.columns)  # Ø§Ù„Ù‚ÙŠÙ…
df_clean = pd.concat([df_values, df_index_flat], axis=1)

# Ù†Ø­Ø¯Ø¯ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆÙ†ØªØ£ÙƒØ¯ Ù…Ù† ØªÙ†Ø³ÙŠÙ‚Ù‡
if 'Date' not in df_clean.columns:
    df_clean.rename(columns={df_clean.columns[-1]: 'Date'}, inplace=True)
df_clean['Date'] = pd.to_datetime(df_clean['Date'])

daily_sentiment_clean = daily_sentiment.reset_index()
daily_sentiment_clean.columns = ['Date', 'sentiment_score']
daily_sentiment_clean['Date'] = pd.to_datetime(daily_sentiment_clean['Date'])

merged = pd.merge(df_clean, daily_sentiment_clean, on='Date', how='left')
merged['sentiment_score'].fillna(0, inplace=True)

print(merged.columns.tolist())

print(merged.columns.tolist())

print(merged.columns.tolist())

# ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
merged.columns = ['_'.join(col) if isinstance(col, tuple) else col for col in merged.columns]

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 6))
plt.plot(merged['Date'], merged['close_GALA-USD'], label='GALA Price', color='blue', linewidth=2)
plt.plot(merged['Date'], merged['sentiment_score'], label='Sentiment Score', color='orange', linewidth=2)
plt.title('GALA Price vs. News Sentiment Over Time')
plt.xlabel('Date')
plt.ylabel('Value')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

correlation = merged['sentiment_score'].corr(merged['close_GALA-USD'])
print(f"Correlation: {correlation:.3f}")

# ğŸ“¥ Step 1: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ğŸ§  Step 2: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
# ğŸ”— Step 3: Ø§Ù„Ø¯Ù…Ø¬
# ğŸ“Š Step 4: Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import yfinance as yf
# from textblob import TextBlob
# import feedparser
# from sklearn.linear_model import LinearRegression
# import matplotlib.pyplot as plt
# 
# st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª ÙˆØ§Ù„Ù…Ø´Ø§Ø¹Ø±", layout="wide")
# st.title("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø³Ø¹Ø± Ø§Ù„Ø¹Ù…Ù„Ø© Ù…Ù‚Ø§Ø¨Ù„ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±")
# 
# # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ø¹Ù…Ù„Ø©
# ticker = st.text_input("ğŸ” Ø£Ø¯Ø®Ù„ Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© (Ù…Ø«Ù„Ø§Ù‹ GALA-USD)", "GALA-USD")
# 
# # ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù…ÙŠÙ„
# start = st.date_input("ğŸ“… Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©", pd.to_datetime("2024-01-01"))
# end = st.date_input("ğŸ“… Ø§Ù„Ù†Ù‡Ø§ÙŠØ©", pd.to_datetime("2025-07-01"))
# 
# if st.button("ğŸš€ Ø´ØºÙ‘Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„"):
#     # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø³Ø¹Ø±
#     price_data = yf.download(ticker, start=start, end=end)
#     price_data = price_data[['Close']].rename(columns={'Close': 'price'})
#     price_data['Date'] = price_data.index
#     price_data.reset_index(drop=True, inplace=True)
# 
#     # Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØ§Ù„Ù…Ø´Ø§Ø¹Ø±
#     def fetch_google_news_rss(query="crypto"):
#         url = f"https://news.google.com/rss/search?q={query.replace(' ', '+')}&hl=en-US&gl=US&ceid=US:en"
#         feed = feedparser.parse(url)
#         data = [{'title': entry.title, 'description': entry.description, 'date': entry.published} for entry in feed.entries]
#         df = pd.DataFrame(data)
#         df['date'] = pd.to_datetime(df['date']).dt.date
#         return df
# 
#     def analyze_sentiment(text):
#         if not text:
#             return 0
#         return TextBlob(text).sentiment.polarity
# 
#     news_df = fetch_google_news_rss(query=ticker.split("-")[0] + " crypto")
#     news_df['sentiment_score'] = news_df['description'].apply(analyze_sentiment)
#     news_df['Date'] = pd.to_datetime(news_df['date'])
#     daily_sentiment = news_df.groupby('Date')['sentiment_score'].mean().reset_index()
# 
#     # Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„ØªÙˆÙ‚Ø¹
#     merged = pd.merge(price_data, daily_sentiment, on='Date', how='left')
#     merged['sentiment_score'].fillna(0, inplace=True)
#     merged['lagged_sentiment'] = merged['sentiment_score'].shift(1)
#     merged.dropna(inplace=True)
# 
#     model = LinearRegression()
#     model.fit(merged[['lagged_sentiment']], merged['price'])
#     merged['predicted_price'] = model.predict(merged[['lagged_sentiment']])
# 
#     # Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
#     st.subheader("ğŸ“ˆ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„ÙØ¹Ù„ÙŠ ÙˆØ§Ù„ØªÙˆÙ‚Ø¹ Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±")
#     fig, ax = plt.subplots(figsize=(12, 5))
#     ax.plot(merged['Date'], merged['price'], label='Ø§Ù„Ø³Ø¹Ø± Ø§Ù„ÙØ¹Ù„ÙŠ', color='blue')
#     ax.plot(merged['Date'], merged['predicted_price'], label='Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹', color='green')
#     ax.set_xlabel("Ø§Ù„ØªØ§Ø±ÙŠØ®")
#     ax.set_ylabel("Ø§Ù„Ø³Ø¹Ø±")
#     ax.legend()
#     st.pyplot(fig)
# 
#     # Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
#     correlation = merged['price'].corr(merged['sentiment_score'])
#     st.success(f"ğŸ’¡ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„Ø³Ø¹Ø± ÙˆØ§Ù„Ù…Ø´Ø§Ø¹Ø±: {correlation:.3f}")
#
